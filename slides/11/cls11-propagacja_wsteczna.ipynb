{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = \"\"\"\n",
    "<style>\n",
    ".output_png { text-align:  center; }\n",
    "</style>\n",
    "    \"\"\"\n",
    "    return HTML(styles)\n",
    "css_styling()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Wykład 11\n",
    "# Wielowarstwowe sieci neuronowe<br/>- propagacja wsteczna błędu\n",
    "04.01.2017 r."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "input_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sieci wielowarstwowe\n",
    "\n",
    "a.k.a. _Artificial Neural Network_ (ANN), _Multi-Layer Perceptron_ (MLP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"nn1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Architektura sieci\n",
    "\n",
    "* Budowa warstwowa, najczęściej sieci jednokierunkowe i gęste.\n",
    "* Liczbę i rozmiar warstw dobiera się do każdego problemu.\n",
    "* Rozmiary sieci określane poprzez liczbę neuronów lub parametrów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "input_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Feedforward #1\n",
    "\n",
    "* Mając daną $n$-warstwową sieć neuronową oraz jej parametry $\\Theta^{(1)}, \\ldots, \\Theta^{(L)} $ oraz $\\beta^{(1)}, \\ldots, \\beta^{(L)} $ liczymy:<br/><br/> \n",
    "$$a^{(l)} = g^{(l)}\\left( a^{(l-1)} \\Theta^{(l)} + \\beta^{(l)} \\right). $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "hide_input": true,
    "input_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"nn2.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "input_collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Feedforward #2\n",
    "\n",
    "* Funkcje $g^{(l)}$ to **funkcje aktywacji**.<br/>\n",
    "Dla $i = 0$ przyjmujemy $a^{(0)} = \\mathrm{x}$ (wektor wierszowy cech) oraz $g^{(0)}(x) = x$ (identyczność)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "input_collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Parametry $\\Theta$ to wagi na połączeniach miedzy neuronami dwóch warstw.<br/>\n",
    "Rozmiar macierzy $\\Theta^{(l)}$, czyli macierzy wag na połączeniach warstw $a^{(l-1)}$ i $a^{(l)}$, to $\\dim(a^{(l-1)}) \\times \\dim(a^{(l)})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "input_collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Parametry $\\beta$ zastępują tutaj dodawanie kolumny z jedynkami do macierzy cech.<br/>Macierz $\\beta^{(l)}$ ma rozmiar równy liczbie neuronów w odpowiedniej warstwie, czyli $1 \\times \\dim(a^{(l)})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "input_collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Feedforward #3\n",
    "\n",
    "* **Klasyfikacja**: dla ostatniej warstwy $L$ (o rozmiarze równym liczbie klas) przyjmuje się $g^{(L)}(x) = \\mathop{\\mathrm{softmax}}(x)$.\n",
    "* **Regresja**: pojedynczy neuron wyjściowy; funkcją aktywacji może wtedy być np. funkcja identycznościowa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "input_collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Pozostałe funkcje aktywacji najcześciej mają postać sigmoidy, np. sigmoidalna, tangens hiperboliczny.<br/> Ale niekoniecznie, np. ReLU, leaky ReLU, maxout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Co z uczeniem sieci?\n",
    "\n",
    "Do trenowania wcześniejszych modeli potrzebowaliśmy:\n",
    "\n",
    "* funkcję kosztu,\n",
    "* gradienty funkcji kosztu,\n",
    "* algorytm SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Propagacja wsteczna<br >- wprowadzenie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem:** mając daną funkcję $f(x)$, gdzie $x$ to wektor wejściowy, chcemy obliczyć $\\nabla f(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* W przypadku sieci neuronowych, $f$ to funkcja kosztu $J$, a $x$ to dane trenujące i parametry sieci.\n",
    "* W praktyce interesują nas gradienty dla parametrów $\\theta$ i $\\beta$.\n",
    "* Dane trenujące traktujemy jako dane i ustalone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1. Pochodna\n",
    "\n",
    "$$f(x,y) = x y \\hspace{0.5in} \\rightarrow \\hspace{0.5in} \\frac{\\partial f}{\\partial x} = y \\hspace{0.5in} \\frac{\\partial f}{\\partial y} = x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Pochodna:** miara szybkości zmian wartości funkcji względem zmian jej argumentów.\n",
    "\n",
    "$$\\frac{df(x)}{dx} = \\lim_{h\\ \\to 0} \\frac{f(x + h) - f(x)}{h}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Na przykład:\n",
    "$x = 4, y = -3$, to $f(x,y) = -12$ i $\\frac{\\partial f}{\\partial x} = -3$\n",
    "\n",
    "* Jeżeli zwiększymy wartość $x$ o niewielką wartość, całe wyrażenie zmniejszy się trzykrotnie.\n",
    "\n",
    "Analogicznie $\\frac{\\partial f}{\\partial y} = 4$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Pochodna cząstkowa względem każdej zmiennej mówi jak wrażliwe jest całe wyrażenie na zmiany wartości tej zmiennej.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Gradient $\\nabla f$ to wektor pochodnych cząstkowych: \n",
    "\n",
    "$$\\nabla f = [\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}] = [y, x]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Suma:\n",
    "$$f(x,y) = x + y \\hspace{0.3in} \\rightarrow \\hspace{0.3in} \\frac{\\partial f}{\\partial x} = 1, \\hspace{0.3in} \\frac{\\partial f}{\\partial y} = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Maksimum:\n",
    "$$f(x,y) = \\max(x, y) \\hspace{0.3in} \\rightarrow \\hspace{0.3in} \\frac{\\partial f}{\\partial x} = \\mathbb{1}(x >= y), \\hspace{0.3in} \\frac{\\partial f}{\\partial y} = \\mathbb{1}(y >= x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2. Funkcje złożone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "$f(x,y,z) = (x + y) z$\n",
    "\n",
    "* Wyrażenie można rozbić: $q = x + y$ i $f = q z$:\n",
    "$$\\frac{\\partial f}{\\partial q} = z, \\frac{\\partial f}{\\partial z} = q$$ \n",
    "$$\\frac{\\partial q}{\\partial x} = 1, \\frac{\\partial q}{\\partial y} = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Reguła łańcuchowa:\n",
    "$$\\frac{\\partial f}{\\partial x} = \\frac{\\partial f}{\\partial q} \\frac{\\partial q}{\\partial x}$$\n",
    "$$\\frac{\\partial f}{\\partial y} = \\frac{\\partial f}{\\partial q} \\frac{\\partial q}{\\partial y}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# wejście jest ustalone\n",
    "x = -2; y = 5; z = -4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 -12\n"
     ]
    }
   ],
   "source": [
    "# krok w przód\n",
    "q = x + y\n",
    "f = q * z\n",
    "print(q, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4, -4, 3]\n"
     ]
    }
   ],
   "source": [
    "# backprop dla f = q * z\n",
    "dz = q\n",
    "dq = z\n",
    "# backprop dla q = x + y\n",
    "dx = 1 * dq # reguła łańcuchowa!\n",
    "dy = 1 * dq # reguła łańcuchowa!\n",
    "\n",
    "print([dx, dy, dz])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"exp1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3. Modułowość obliczeń"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Funkcja sigmoidalna:\n",
    "\n",
    "$$f(\\theta,x) = \\frac{1}{1+e^{-(\\theta_0 x_0 + \\theta_1 x_1 + \\theta_2)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\begin{array}{lcl}\n",
    "f(x) = \\frac{1}{x} \\hspace{.3in} & \\rightarrow & \\hspace{.4in} \\frac{df}{dx} = -1/x^2 \n",
    "\\\\[2mm]\n",
    "f_c(x) = c + x \\hspace{.3in} & \\rightarrow & \\hspace{.4in} \\frac{df}{dx} = 1 \n",
    "\\\\[2mm]\n",
    "f(x) = e^x \\hspace{.3in} & \\rightarrow & \\hspace{.4in} \\frac{df}{dx} = e^x\n",
    "\\\\[2mm]\n",
    "f_a(x) = ax \\hspace{.3in} & \\rightarrow & \\hspace{.4in} \\frac{df}{dx} = a\n",
    "\\\\[2mm]\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"exp2.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}} \\hspace{0.3in} \\rightarrow \\hspace{0.3in} \\frac{d\\sigma(x)}{dx} = \\left( 1 - \\sigma(x) \\right) \\sigma(x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3932238664829637, -0.5898357997244456]\n",
      "[-0.19661193324148185, -0.3932238664829637, 0.19661193324148185]\n"
     ]
    }
   ],
   "source": [
    "# losowe wagi i dane\n",
    "w = [2,-3,-3]\n",
    "x = [-1, -2]\n",
    "\n",
    "# krok w przód\n",
    "dot = w[0]*x[0] + w[1]*x[1] + w[2]\n",
    "f = 1.0 / (1 + math.exp(-dot)) # sigmoid\n",
    "\n",
    "# krok w tył\n",
    "ddot = (1 - f) * f # pochodna sigmoid\n",
    "dx = [w[0] * ddot, w[1] * ddot]\n",
    "dw = [x[0] * ddot, x[1] * ddot, 1.0 * ddot]\n",
    "\n",
    "print(dx)\n",
    "print(dw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4. Przykład"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "$$f(x,y) = \\frac{x + \\sigma(y)}{\\sigma(x) + (x+y)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = 3 # example values\n",
    "y = -4\n",
    "\n",
    "# forward pass\n",
    "sigy = 1.0 / (1 + math.exp(-y)) # sigmoid in numerator   #(1)\n",
    "num = x + sigy # numerator                               #(2)\n",
    "sigx = 1.0 / (1 + math.exp(-x)) # sigmoid in denominator #(3)\n",
    "xpy = x + y                                              #(4)\n",
    "xpysqr = xpy**2                                          #(5)\n",
    "den = sigx + xpysqr # denominator                        #(6)\n",
    "invden = 1.0 / den                                       #(7)\n",
    "f = num * invden # done!                                 #(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# backprop f = num * invden\n",
    "dnum = invden # gradient on numerator                             #(8)\n",
    "dinvden = num                                                     #(8)\n",
    "# backprop invden = 1.0 / den \n",
    "dden = (-1.0 / (den**2)) * dinvden                                #(7)\n",
    "# backprop den = sigx + xpysqr\n",
    "dsigx = (1) * dden                                                #(6)\n",
    "dxpysqr = (1) * dden                                              #(6)\n",
    "# backprop xpysqr = xpy**2\n",
    "dxpy = (2 * xpy) * dxpysqr                                        #(5)\n",
    "# backprop xpy = x + y\n",
    "dx = (1) * dxpy                                                   #(4)\n",
    "dy = (1) * dxpy                                                   #(4)\n",
    "# backprop sigx = 1.0 / (1 + math.exp(-x))\n",
    "dx += ((1 - sigx) * sigx) * dsigx # Notice += !!                  #(3)\n",
    "# backprop num = x + sigy\n",
    "dx += (1) * dnum                                                  #(2)\n",
    "dsigy = (1) * dnum                                                #(2)\n",
    "# backprop sigy = 1.0 / (1 + math.exp(-y))\n",
    "dy += ((1 - sigy) * sigy) * dsigy                                 #(1)\n",
    "# done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5. Wzorce zmian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* **add**: kopiuje gradient z wyjścia do każdego wejścia\n",
    "* **max**: kopiuje wyjście do wejścia o największej wartości, reszta 0\n",
    "* **mul**: wejściowe gradienty są mnożone przez wyjściowy i zamieniane miejscami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"exp3.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Podsumowanie\n",
    "\n",
    "* Gradient $f$ dla $x$ mówi jak zmieni się całe wyrażenie przy zmianie wartości $x$.\n",
    "* Gradienty łączymy korzystając z **reguły łańcuchowej**.\n",
    "* W kroku wstecz gradienty informują które części grafu powinny być zwiększone lub zmniejszone (i z jaką siłą), aby zwiększyć wartość na wyjściu.\n",
    "* W kontekście implementacji chcemy dzielić funkcję $f$ na części, dla których można łatwo obliczyć gradienty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Uczenie wielowarstwowych sieci neuronowych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Mając algorytm SGD oraz gradienty wszystkich wag, moglibyśmy trenować każdą sieć."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Niech:\n",
    "$$\\Theta = (\\Theta^{(1)},\\Theta^{(2)},\\Theta^{(3)},\\beta^{(1)},\\beta^{(2)},\\beta^{(3)})$$\n",
    "\n",
    "* Funkcja sieci neuronowej z grafiki:\n",
    "\n",
    "$$\\small h_\\Theta(x) = \\tanh(\\tanh(\\tanh(x\\Theta^{(1)}+\\beta^{(1)})\\Theta^{(2)} + \\beta^{(2)})\\Theta^{(3)} + \\beta^{(3)})$$\n",
    "* Funkcja kosztu dla regresji:\n",
    "$$J(\\Theta) = \\dfrac{1}{2m} \\sum_{i=1}^{m} (h_\\Theta(x^{(i)})- y^{(i)})^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Jak obliczymy gradienty?\n",
    "\n",
    "$$\\nabla_{\\Theta^{(l)}} J(\\Theta) = ? \\quad \\nabla_{\\beta^{(l)}} J(\\Theta) = ?$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## W kierunku propagacji wstecznej\n",
    "\n",
    "* Pewna (niewielka) zmiana wagi $\\Delta z^l_j$ dla $j$-ego neuronu w warstwie $l$ pociąga za sobą (niewielką) zmianę kosztu: \n",
    "\n",
    "$$\\frac{\\partial J(\\Theta)}{\\partial z^{l}_j}  \\Delta z^{l}_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Jeżeli $\\frac{\\partial J(\\Theta)}{\\partial z^{l}_j}$ jest duża, $\\Delta z^l_j$ ze znakiem przeciwnym zredukuje koszt.\n",
    "* Jeżeli $\\frac{\\partial J(\\Theta)}{\\partial z^l_j}$ jest bliska zeru, koszt nie będzie wiele poprawiony."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Definiujemy błąd $\\delta^l_j$ neuronu $j$ w warstwie $l$: \n",
    "\n",
    "$$\\delta^l_j \\equiv \\dfrac{\\partial J(\\Theta)}{\\partial z^l_j}$$ \n",
    "$$\\delta^l \\equiv \\nabla_{z^l} J(\\Theta) \\textrm{ (zapis wektorowy)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Podstawowe równania propagacji wstecznej\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccll}\n",
    "\\delta^L & = & \\nabla_{a^L}J(\\Theta) \\odot {(g^{L})}^{\\prime}(z^L) & (BP1) \\\\[2mm]\n",
    "\\delta^{l} & = & ((\\Theta^{l+1})^T \\delta^{l+1}) \\odot {{(g^{l})}^{\\prime}}(z^{l}) & (BP2)\\\\[2mm]\n",
    "\\nabla_{\\beta^l} J(\\Theta) & = & \\delta^l & (BP3)\\\\[2mm]\n",
    "\\nabla_{\\Theta^l} J(\\Theta) & = & a^{l-1} \\odot \\delta^l & (BP4)\\\\\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Algorytm propagacji wstecznej\n",
    "\n",
    "Dla jednego przykładu (x,y):\n",
    "\n",
    "1. **Wejście**: Ustaw aktywacje w warstwie cech $a^{(0)}=x$ \n",
    "2. **Feedforward:** dla $l=1,\\dots,L$ oblicz \n",
    "$$z^{(l)} = a^{(l-1)} \\Theta^{(l)} + \\beta^{(l)} \\textrm{ oraz } a^{(l)}=g^{(l)}(z^{(l)})$$\n",
    "3. **Błąd wyjścia $\\delta^{(L)}$:** oblicz wektor $$\\delta^{(L)}= \\nabla_{a^{(L)}}J(\\Theta) \\odot {g^{\\prime}}^{(L)}(z^{(L)})$$\n",
    "4. **Propagacja wsteczna błędu:** dla $l = L-1,L-2,\\dots,1$ oblicz $$\\delta^{(l)} = \\delta^{(l+1)}(\\Theta^{(l+1)})^T \\odot {g^{\\prime}}^{(l)}(z^{(l)})$$\n",
    "5. **Gradienty:** \n",
    "    * $\\dfrac{\\partial}{\\partial \\Theta_{ij}^{(l)}} J(\\Theta) = a_i^{(l-1)}\\delta_j^{(l)} \\textrm{ oraz } \\dfrac{\\partial}{\\partial \\beta_{j}^{(l)}} J(\\Theta) = \\delta_j^{(l)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "W naszym przykładzie:\n",
    "\n",
    "$$\\small J(\\Theta) = \\frac{1}{2}(a^{(L)} - y)^2 $$\n",
    "$$\\small  \\dfrac{\\partial}{\\partial a^{(L)}} J(\\Theta) = a^{(L)} - y$$\n",
    "\n",
    "$$\\small \\tanh^{\\prime}(x) = 1 - \\tanh^2(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "hide_input": true,
    "input_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"nn3.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## SGD z propagacją wsteczną\n",
    "\n",
    "Jedna iteracja:\n",
    "* Dla parametrów $\\Theta = (\\Theta^{(1)},\\ldots,\\Theta^{(L)})$ utwórz pomocnicze macierze zerowe $\\Delta = (\\Delta^{(1)},\\ldots,\\Delta^{(L)})$ o takich samych wymiarach (dla uproszczenia opuszczono wagi $\\beta$).\n",
    "* Dla $m$ przykładów we wsadzie (batch), $i = 1,\\ldots,m$:\n",
    "    * Wykonaj algortym propagacji wstecznej dla przykładu $(x^{(i)}, y^{(i)})$ i przechowaj gradienty $\\nabla_{\\Theta}J^{(i)}(\\Theta)$ dla tego przykładu;\n",
    "    * $\\Delta := \\Delta + \\dfrac{1}{m}\\nabla_{\\Theta}J^{(i)}(\\Theta)$\n",
    "* Wykonaj aktualizację wag: $\\Theta := \\Theta - \\alpha \\Delta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Podsumowanie\n",
    "\n",
    "* Algorytm pierwszy raz wprowadzony w latach 70.\n",
    "* W 1986 David Rumelhart, Geoffrey Hinton, i Ronald Williams pokazali, że jest znacznie szybszy od wcześniejszych metod.\n",
    "* Obecnie najpopularniejszy algorytm uczenia sieci neuronowych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reverse-mode automatic differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Metoda obliczania gradientu dowolnej funkcji.\n",
    "\n",
    "Propagacja wsteczna jest szczególnym przypadkiem tej metody.\n",
    "\n",
    "Przykład dla:\n",
    "\n",
    "$$f(x_1,x_2) = \\sin(x_1) + x_1x_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img  style=\"margin: auto\" height=\"80%\" src=\"ad0.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img  style=\"margin: auto\" height=\"80%\" src=\"ad1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Idea za _reverse-mode auto-diff_:\n",
    "\n",
    "* Powtarzaj zamianę pochodnych funkcji zewnętrznych korzystając z reguły łańcuchowej;\n",
    "* Każde podwyrażenie jest podyktowane strukturą grafu.\n",
    "\n",
    "$$ \\small\n",
    "\\dfrac{\\partial f}{\\partial x} \n",
    "= \\dfrac{\\partial f}{\\partial w_1} \\dfrac{\\partial w_1}{\\partial x} \n",
    "= \\left(\\dfrac{\\partial f}{\\partial w_2} \\dfrac{\\partial w_2}{\\partial w_1} \\right) \\dfrac{\\partial w_1}{\\partial x} \n",
    "= \\left(\\left(\\dfrac{\\partial f}{\\partial w_3}\\dfrac{\\partial w_3}{\\partial w_2}\\right) \\dfrac{\\partial w_2}{\\partial w_1} \\right) \\dfrac{\\partial w_1}{\\partial x} \n",
    "= \\ldots\n",
    "$$\n",
    "\n",
    "* Obliczamy ***adjoint***: \n",
    "\n",
    "$$ \\bar{w} = \\frac{\\partial f}{\\partial w} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img style=\"margin: auto\" height=\"80%\" src=\"ad2.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 2-layer Neural Network in Marian\n",
    "\n",
    "```cpp\n",
    "    auto x = input(shape={whatevs, 784});\n",
    "    auto y = input(shape={whatevs, 10});\n",
    "  \n",
    "    auto w1 = param(shape={784, 100});\n",
    "    auto b1 = param(shape={1, 100});\n",
    "    auto l1 = tanh(dot(x, w1) + b1);\n",
    "    \n",
    "    auto w2 = param(shape={100, 10});\n",
    "    auto b2 = param(shape={1, 10});\n",
    "    auto l2 = softmax(dot(l1, w2) + b2, axis=1);\n",
    "    \n",
    "    auto graph = -mean(sum(y * log(l2), axis=1), \n",
    "                           axis=0);\n",
    "  \n",
    "    x = Tensor({500, 784}, 1);\n",
    "    y = Tensor({500, 10}, 1);\n",
    "  \n",
    "    graph.forward();\n",
    "    graph.backward();\n",
    "  \n",
    "    auto dw = w.grad();\n",
    "    auto db = b.grad();\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Unary node for Tanh operation in Marian\n",
    "\n",
    "```cpp\n",
    "struct TanhNodeOp : public UnaryNodeOp {\n",
    "  template <typename ...Args>\n",
    "  TanhNodeOp(Args ...args)\n",
    "  : UnaryNodeOp(args...) { }\n",
    "  \n",
    "  void forward() {\n",
    "    Element(_1 = Tanh(_2),\n",
    "            val_, a_->val());\n",
    "  }\n",
    "  \n",
    "  void backward() {\n",
    "    Element(_1 += _2 * (1 - Tanh(_3) * Tanh(_3)),\n",
    "            a_->grad(), adj_, a_->val());\n",
    "  }\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Źródła\n",
    "\n",
    "* http://cs231n.github.io/optimization-2/\n",
    "* https://github.com/emjotde/mt-marathon/blob/master/lec02/\n",
    "* http://neuralnetworksanddeeplearning.com/chap2.html\n",
    "* https://github.com/emjotde/Marian"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
