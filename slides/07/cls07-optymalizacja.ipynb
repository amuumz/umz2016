{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "hide_input": false,
    "input_collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "def css_styling():\n",
    "    styles = \"\"\"\n",
    "<style>\n",
    ".output_png { text-align:  center; }\n",
    "</style>\n",
    "    \"\"\"\n",
    "    return HTML(styles)\n",
    "css_styling()\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "input_collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def runMeanFast(x, N):\n",
    "    return np.convolve(x, np.ones((N,))/N, mode='valid')\n",
    "\n",
    "def safeSigmoid(x, eps=0.0):\n",
    "    y = 1.0/(1.0 + np.exp(-x))\n",
    "    # przytnij od dolu i gory\n",
    "    if eps > 0:\n",
    "        y[y < eps] = eps\n",
    "        y[y > 1 - eps] = 1 - eps\n",
    "    return y\n",
    "\n",
    "def h(theta, X, eps=0.0):\n",
    "    return safeSigmoid(X*theta, eps)\n",
    "\n",
    "def J(h,theta,X,y):\n",
    "    m = len(y)\n",
    "    f = h(theta, X, eps=10**-7)\n",
    "    return -np.sum(np.multiply(y, np.log(f)) + \n",
    "                   np.multiply(1 - y, np.log(1 - f)), axis=0)/m\n",
    "\n",
    "def dJ(h,theta,X,y):\n",
    "    return 1.0/len(y)*(X.T*(h(theta,X)-y))\n",
    "\n",
    "def softmax(X):\n",
    "    X128 = X.astype(np.float128)\n",
    "    return np.exp(X128)/np.sum(np.exp(X128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wykład 07\n",
    "\n",
    "# Metody optymalizacji\n",
    "\n",
    "* Warianty algorytmu GD*\n",
    "* Metody zbiorcze\n",
    "* Urozmaicenie metod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Déjà vu: Gradient Descent i regresja logistyczna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Regresja logistyczna - model\n",
    "\n",
    "Model regresji logistycznej:\n",
    "\n",
    "$$h_\\theta(X) = g(X\\theta) = \\dfrac{1}{1+e^{-X\\theta}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Regresja logistyczna - Funkcja kosztu\n",
    "\n",
    "Funkcja kosztu dla regresji logistycznej:\n",
    "$$\\small\n",
    "J(\\theta) = -\\dfrac{1}{m} [\\sum_{i=1}^{m} y^{(i)} \\log h_\\theta(x^{(i)})+ (1-y^{(i)}) \\log (1-h_\\theta(x^{(i)}))]$$\n",
    "\n",
    "Gradient funkcji kosztu:\n",
    "\n",
    "$$\\nabla J(\\theta) = \\frac{1}{|\\vec y|} X^T\\left(h_\\theta(X)-\\vec y\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## (Batch) Gradient descent \n",
    "\n",
    "\n",
    "W postaci wektorwej:\n",
    "\n",
    "$$ \\theta_{t+1} = \\theta_{t} - \\alpha \\nabla J(\\theta_{t}) $$\n",
    "\n",
    "lub iteracyjnej:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcll}\n",
    "\\theta_{t+1,j} & := & \\theta_{t,j} - \\alpha \\dfrac{\\partial}{\\partial\\theta_{t,j}}J(\\theta_t) & \\;j=0,\\ldots,n\\\\ \n",
    "\\end{array}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dla regresji logistycznej\n",
    "\n",
    "Wykonaj określoną liczbę razy:\n",
    "\n",
    "$$\\small\n",
    "\\begin{array}{rcll}\\small\n",
    "\\theta_{t+1,j} & := & \\theta_{t,j} - \\alpha \\dfrac{1}{m}\\displaystyle\\sum_{i=1}^m (h_{\\theta_{t,j}}(x^{(i)})-y^{(i)})x^{(i)}& j=0,\\ldots,n\\\\ \\\\ \n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Część 1.\n",
    "# Warianty algorytmu Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Gradient descent:**\n",
    "\n",
    "* Powtórz określoną liczbę razy (liczba epok):\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\theta_{t+1,j} := \\theta_{t,j} - \\alpha \\dfrac{1}{m}\\displaystyle\\sum_{i=1}^m (h_{\\theta_{t,j}}(x^{(i)})-y^{(i)})x^{(i)}\\\\ \n",
    "(\\textrm{dla } j=0,\\ldots,n)\\\\\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_Epoka_ to jednokrotne przejście przez wszystkie dane uczące."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Stochastic Gradient Descent:**\n",
    "\n",
    "* Randomizuj dane treningowe\n",
    "* Powtórz określoną liczbę razy (liczba epok):\n",
    "  * Powtórz dla każdego $i=1,\\dots,m$:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\theta_{t+1,j} := \\theta_{t,j} - \\alpha (h_{\\theta_{t,j}}(x^{(i)})-y^{(i)})x^{(i)} \\\\\n",
    "(\\textrm{dla } j=0,\\ldots,n)\\\\\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_Randomizacja danych_ to losowe potasowanie przykładów uczących (wspólnie z odpowiedziami). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Dyskusja:\n",
    "\n",
    "* Ile uaktualnień parametru $\\theta$ wykonuje algorytm SGD podczas jednej epoki? \n",
    "* Ile uaktualnień wykonuje algorytm (Batch) GD?\n",
    "* Co daje randomizacja danych w przypadku SGD?\n",
    "* Czy randomizacja może pomóc w GD?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Mini-Batch Gradient Descent:**\n",
    "\n",
    "* Ustal rozmiar wsadu (\"batch\") $b \\le m$ \n",
    "* Randomizuj dane treningowe\n",
    "* Powtórz określoną liczbę razy (liczba epok):\n",
    "  * Powtórz dla każdego $i=1,1+b,1+2b,\\dots,m-b+1$:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\theta_{t+1,j} := \\theta_{t,j} - \\alpha \\dfrac{1}{b} \\displaystyle\\sum_{k=i}^{i+b-1} (h_{\\theta_{t,j}}(x^{(k)})-y^{(k)})x^{(k)} \\\\\n",
    "(\\textrm{dla } j=0,\\ldots,n)\\\\\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Typowe wartości dla $b$ to od kilku przykładów do kilkuset, tj. małe w porównaniu do $m$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dyskusja:\n",
    "\n",
    "* Znając $m$ i $b$, ile razy zostanie uaktualniony parametr $\\theta$?\n",
    "* Jak mają się SGD oraz GD do Mini-Batch SGD?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Mini-Batch SGD - implementacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def MiniBatchSGD(h, fJ, fdJ, theta, X, y, \n",
    "        alpha=0.001, maxEpochs=1.0, batchSize=100, \n",
    "        logError=True):\n",
    "    errorsX, errorsY = [], []\n",
    "    \n",
    "    m, n = X.shape\n",
    "    start, end = 0, batchSize\n",
    "    \n",
    "    maxSteps = (m * float(maxEpochs)) / batchSize\n",
    "    for i in range(int(maxSteps)):\n",
    "        XBatch, yBatch =  X[start:end,:], y[start:end,:]\n",
    "\n",
    "        theta = theta - alpha * fdJ(h, theta, XBatch, yBatch)\n",
    "        \n",
    "        if logError:\n",
    "            errorsX.append(float(i*batchSize)/m)\n",
    "            errorsY.append(fJ(h, theta, XBatch, yBatch).item())\n",
    "        \n",
    "        if start + batchSize < m:\n",
    "            start += batchSize\n",
    "        else:\n",
    "            start = 0\n",
    "        end = min(start + batchSize, m)\n",
    "        \n",
    "    return theta, (errorsX, errorsY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Porównanie GD, SGD, Mini-Batch SGD \n",
    "\n",
    "Na przykładzie MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "hide_input": false,
    "input_collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAAHiCAYAAADcelBQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAHAaF7YAAAAAAKdxYQsAAAAAcNr/ApIfHCAHB90UAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc4ad165940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import matplotlib as mpl\n",
    "\n",
    "np.seterr(over=\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "def readMnist(dataset = \"training\", path = \".\"):\n",
    "    \"\"\"\n",
    "    Python function for importing the MNIST data set.  It returns an iterator\n",
    "    of 2-tuples with the first element being the label and the second element\n",
    "    being a numpy.uint8 2D array of pixel data for the given image.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset is \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset is \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "    else:\n",
    "        raise(ValueError, \"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    # Load everything in some numpy arrays\n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "\n",
    "    get_img = lambda idx: (lbl[idx], img[idx])\n",
    "\n",
    "    # Create an iterator which returns each image in turn\n",
    "    for i in range(len(lbl)):\n",
    "        yield get_img(i)\n",
    "\n",
    "def showImage(image, r=1, c=1, i=1, fig=None):\n",
    "    \"\"\"\n",
    "    Render a given numpy.uint8 2D array of pixel data.\n",
    "    \"\"\"\n",
    "    if fig is None:\n",
    "        fig = pyplot.figure()\n",
    "    ax = fig.add_subplot(r,c,i)\n",
    "    ax.set_xticks([]) \n",
    "    ax.set_yticks([]) \n",
    "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    if fig is None:\n",
    "        ax.xaxis.set_ticks_position('top')\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "        pyplot.show()    \n",
    "    \n",
    "def showImageGrid(data, r, c):\n",
    "    fig = pyplot.figure(figsize=(c*1.5,r*1.5))\n",
    "    for i,row in enumerate(data[:r*c]):\n",
    "        image = row[:, 1:].reshape(28,28)\n",
    "        showImage(image, r, c, i+1, fig)\n",
    "    pyplot.show()\n",
    "\n",
    "    \n",
    "def toMatrix(data, maxItems=60000):\n",
    "    datalist = [t for t in data]\n",
    "    np.random.shuffle(datalist) # randomizacja danych\n",
    "    m = len(datalist)\n",
    "    n = 28 * 28 + 1\n",
    "    X = np.matrix(np.zeros(m * n)).reshape(m, n)\n",
    "    Y = np.matrix(np.zeros(m)).reshape(m, 1)\n",
    "    for i, (label, image) in enumerate(datalist[:maxItems]):\n",
    "        X[i, 0] = 1 # bias term\n",
    "        X[i, 1:] = image.reshape(28*28,)\n",
    "        Y[i] = label\n",
    "    return X, Y\n",
    "\n",
    "def mapY(y, cls):\n",
    "    m = len(y)\n",
    "    yBi = np.matrix(np.zeros(m)).reshape(m, 1)\n",
    "    yBi[y == cls] = 1.\n",
    "    return yBi\n",
    "\n",
    "def indicatorMatrix(y):\n",
    "    classes = np.unique(y.tolist())\n",
    "    m = len(y)\n",
    "    k = len(classes)\n",
    "    Y = np.matrix(np.zeros((m, k)))\n",
    "    for i, cls in enumerate(classes):\n",
    "        Y[:,i] = mapY(y, cls)\n",
    "    return Y\n",
    "\n",
    "dataDir = \"../../labs/06\"\n",
    "\n",
    "mnistTrain = readMnist(\"training\", path=dataDir)\n",
    "mnistTest = readMnist(\"testing\", path=dataDir)\n",
    "\n",
    "XTrain, YTrain = toMatrix(mnistTrain)\n",
    "XTest, YTest = toMatrix(mnistTest)\n",
    "\n",
    "YTrain = indicatorMatrix(YTrain)\n",
    "YTest = indicatorMatrix(YTest)\n",
    "\n",
    "k = YTest.shape[1]\n",
    "\n",
    "showImageGrid(XTrain, 4, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Krzywe uczenia <br/>dla binarnej regresji logistycznej\n",
    "### (liczba 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "hide_input": false,
    "input_collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<img src=\"sgd1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Uśrednione krzywe uczenia <br/>dla binarnej regresji logistycznej\n",
    "#### (liczba 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "hide_input": false,
    "input_collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<img src=\"sgd2.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SGD vs GD\n",
    "\n",
    "* SGD jest znacznie szybszy i często daje lepsze wyniki\n",
    "* Warianty SGD, gdzie $b \\ll m$ (znacząco mniejsze) nazywa się też algorytmami **on-line**\n",
    "* Dane uczące są bardzo duże, a nawet nieograniczone (*uczenie on-line*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dyskusja \n",
    "* Czy SGD można przerwać i wznowić? Jeśli tak, kiedy?\n",
    "* O co trzeba zadbać? Co trzeba zapisać?\n",
    "* W najgorszym przypadku, ile informacji stracimy?\n",
    "* Czy można wykorzystać częsciowe wyniki?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Google: Downpour SGD (J. Dean ***et al.***)\n",
    "<br/>\n",
    "<img src=\"downpour.png\" width=\"85%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Inne warianty SGD:\n",
    "\n",
    "* Nesterov accelerated gradient (Nesterov, 1983)\n",
    "* SGD with Momentum (Rumelhart *et al.*, 1986)\n",
    "* AdaGrad (Duchi *et al.*, 2011)\n",
    "* Downpour SGD (Dean *et al.*, 2012)\n",
    "* AdaDelta (Google, Zeiler *et al.*, 2012)\n",
    "* RMSprop (Hinton *et al.*, 2012)\n",
    "* v-SGD-{l,g,b} (LeCunn *et al.*, 2012)\n",
    "* Adam (Kingma & Ba, 2015)\n",
    "* ...\n",
    "\n",
    "Od tej pory algorytm GD będziemy traktowali jako wariant SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# AdaGrad\n",
    "\n",
    "J. Duchi *et al.* (2011), *Adaptive Subgradient Methods for Online Learning and Stochastic Optimization*. Journal of Machine Learning Research 12. pp. 2121-2159"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Problemy z naiwnymi metodami SGD\n",
    "\n",
    "* Trudno dobrać rozmiar kroku $\\alpha$\n",
    "* Po zmianie innych parametrów, np. rozmiaru wsadu lub liczby epok, trzeba często na nowo dostroić $\\alpha$\n",
    "* SGD nie radzi sobie zbyt dobrze z cechami nieznormalizowanymi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Dwa usprawnienia**:\n",
    "\n",
    "1. Różne wartości $\\alpha$ w trakcie uczenia\n",
    "1. Osobne $\\alpha$ dla każdego parametru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**SGD** (dowolny wariant) ma jeden stały parametr $\\alpha$.\n",
    "\n",
    "Niech $\\mathbf{g}_t = \\nabla J(\\mathbf{\\theta}_t)$, czyli $g_{t,j} = \\dfrac{\\partial}{\\partial\\theta_{t,j}}J(\\theta_t)$, wtedy SGD ma postać:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\theta_{t+1} := \\theta_{t} - \\alpha \\mathbf{g}_t \\\\\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "W ** AdaGrad ** zastępujemy skalar $\\alpha$ samostrojącymi się krokami $\\alpha_{t,j}$ dla każdej cechy $x_j$ i każdej iteracji $t$:\n",
    "\n",
    "$$\\alpha_{t,j} = \\dfrac{\\alpha}{\\sqrt{\\sum_{t^{\\prime}=1}^tg_{t^{\\prime},j}^2}}$$\n",
    "\n",
    "gdzie $\\sum_{t^{\\prime}=1}^tg_{t^{\\prime},j}^2$ jest sumą kwadratów wszystkich dotychczasowych gradientów (gradienty historyczne)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Oznaczmy\n",
    "\n",
    "$$G_t^{-\\frac{1}{2}} = \\frac{1}{\\sqrt{\\sum_{t^{\\prime}=1}^tg_{t^{\\prime},j}^2}},$$\n",
    "wtedy\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\alpha G_t^{-\\frac{1}{2}}\\odot \\mathbf{g}_t,\n",
    "$$\n",
    "\n",
    "gdzie $\\odot$ to mnożenie elementowe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Intuicja\n",
    "\n",
    "Rzadkie cechy są nośnikami ważnych informacji (i odwrotnie: cecha, która występuje zawsze, mało wnosi).\n",
    "\n",
    "Np. MNIST: piksel, który jest bardzo często czarny, nie pomaga rozstrzygnąć, jaką widzimy liczbę:\n",
    "<img src=\"mean-mnist-img.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## AdaGrad\n",
    "\n",
    "* AdaGrad przydziela częstym cechom wysokie wagi (czyli małe kroki $\\alpha_{t,j}$) i odwrotnie.\n",
    "* Występująca cecha ma niezerowy gradient, zatem sumując kw. gradientów, zliczamy cechy.\n",
    "* Wysokie $\\alpha_{t,j}$ w chwili wystąpienia cechy $x_j$ oznacza \"Zauważ mnie!\".\n",
    "* Możemy ustawić $\\alpha = 1.0$ dla dowolnego problemu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## AdaGrad - implementacja (przedstawiona na wykładzie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Uwaga! To nie jest kompletna funkcja!\n",
    "\n",
    "def SGD(h, fJ, fdJ, theta, X, y, \n",
    "        alpha=0.001, maxEpochs=1.0, batchSize=100, \n",
    "        adaGrad=False, logError=False):\n",
    "    m, n = X.shape\n",
    "    start, end = 0, batchSize\n",
    "    \n",
    "    maxSteps = (m * float(maxEpochs)) / batchSize\n",
    "    for i in range(int(maxSteps)):\n",
    "        XBatch, yBatch =  X[start:end,:], y[start:end,:]\n",
    "\n",
    "        theta = theta - fdJ(h, theta, XBatch, yBatch)\n",
    "        \n",
    "        if start + batchSize < m:\n",
    "            start += batchSize\n",
    "        else:\n",
    "            start = 0\n",
    "        end = min(start + batchSize, m)\n",
    "        \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "input_collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Test na MNIST \n",
    "\n",
    "Ponownie binarny klasyfikator dla cyfry 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "hide_input": false,
    "input_collapsed": true
   },
   "source": [
    "<img src=\"adagrad.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "input_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Jakość klasyfikacji na zbiorze testowym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def classify(thetas, X):\n",
    "    regs = np.array([(X*theta).item() for theta in thetas])\n",
    "    probs = softmax(regs)\n",
    "    return np.argmax(probs), probs\n",
    "\n",
    "def accuracy(models, XTest, YTest, k=10):\n",
    "    acc = [0 for i in range(len(models))]\n",
    "    cls = [0 for i in range(len(models))]\n",
    "\n",
    "    YTestCls = YTest * np.matrix((np.arange(k))).T\n",
    "    for i in range(len(YTestCls)):\n",
    "        for j, model in enumerate(models):\n",
    "            cls[j], probs = classify(model, XTest[i])\n",
    "        correct = int(YTestCls[i].item())\n",
    "    \n",
    "        for j in range(len(cls)):\n",
    "            acc[j] += correct == cls[j]\n",
    "        \n",
    "    n = len(XTest)\n",
    "    return [a / float(n) for a in acc]\n",
    "\n",
    "def trainLogReg(X, Y, **kwargs):\n",
    "    n = X.shape[1]\n",
    "    print(kwargs)\n",
    "    thetas = []\n",
    "    for c in range(Y.shape[1]):\n",
    "        YBi = Y[:,c]\n",
    "        theta = np.matrix(np.random.random(n)).reshape(n,1)\n",
    "        thetaBest = SGD(h, J, dJ, theta, \n",
    "                        X, YBi, \n",
    "                        **kwargs)\n",
    "        print(\".\", end=\"\")\n",
    "        thetas.append(thetaBest)\n",
    "    print(\"Done\")\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batchSize = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "hide_input": true,
    "input_collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adaGrad': False, 'batchSize': 1000, 'maxEpochs': 10, 'alpha': 0.1}\n",
      "..........Done\n",
      "{'adaGrad': False, 'batchSize': 1000, 'maxEpochs': 10, 'alpha': 0.01}\n",
      "..........Done\n",
      "{'adaGrad': False, 'batchSize': 1000, 'maxEpochs': 10, 'alpha': 0.001}\n",
      "..........Done\n",
      "{'adaGrad': True, 'batchSize': 1000, 'maxEpochs': 10, 'alpha': 1}\n",
      "..........Done\n",
      "Acc 0 = 0.8572\n",
      "Acc 1 = 0.7132\n",
      "Acc 2 = 0.7692\n",
      "Acc 3 = 0.7927\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    trainLogReg(XTrain, YTrain, alpha=0.1, maxEpochs=epochs, \n",
    "                batchSize=batchSize, adaGrad=False),\n",
    "    trainLogReg(XTrain, YTrain, alpha=0.01, maxEpochs=epochs, \n",
    "                batchSize=batchSize, adaGrad=False),\n",
    "    trainLogReg(XTrain, YTrain, alpha=0.001, maxEpochs=epochs, \n",
    "                batchSize=batchSize, adaGrad=False),\n",
    "    trainLogReg(XTrain, YTrain, alpha=1, maxEpochs=epochs, \n",
    "                batchSize=batchSize, adaGrad=True)\n",
    "]\n",
    "\n",
    "acc = accuracy(models, XTest, YTest)\n",
    "for j in range(len(models)):\n",
    "    print(\"Acc\", j, \"=\", acc[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "input_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dlaczego nie korzystamy z AdaGrad zawsze?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Wyniki badawcze wskazują na to, że często **starannie** dobrane $\\alpha$ daje lepsze wyniki na zbiorze testowym\n",
    "* Można też dynamicznie zmieniać $\\alpha$ (np. jeśli błąd się nie zmniejszył przez $n$ iteracji, podziel $\\alpha$ przez 2, itp.)\n",
    "* Praktycy uczenia maszynowego nie lubią braku kontroli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**AdaGrad**: dobry algorytm na dobry początek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Jaką metodę optymalizacji wybrać?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "<img src=\"contours_evaluation_optimizers.gif\" style=\"display:inline-block; width:45%\" />\n",
    "<img src=\"saddle_point_evaluation_optimizers.gif\" style=\"display:inline-block; width:50%\"/>\n",
    "</div>\n",
    "\n",
    "Źródło: http://cs231n.github.io/neural-networks-3/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "input_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cześć 2.\n",
    "\n",
    "# Metody zbiorcze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Metody zbiorcze** (_ensemble methods_) używają wielu modeli uczenia maszynowego w celu uzyskania lepszej skuteczności niż mogłaby być osiągnięta przez każdy z tych modeli osobno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Dwa \"parametry\":\n",
    "\n",
    "1. Dobór modelu\n",
    "1. Agregacja wyników"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "input_collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Uśrednianie prawdopodobieństw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Mamy $M=3$ modele, które dla $c=1\\dots5$ klas zwróciły prawdopodobieństwa:\n",
    "\n",
    "* $M_1$: `[0.1, 0.4, 0.5, 0.0, 0.0]`\n",
    "* $M_2$: `[0.1, 0.6, 0.2, 0.0, 0.1]`\n",
    "* $M_3$: `[0.1, 0.3, 0.4, 0.0, 0.2]`\n",
    "\n",
    "Która klasa zostanie wybrana wg średnich prawdopodobieństw dla każdej klasy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "input_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Uśrednianie prawdopodobieństw z randomizacją\n",
    "\n",
    "Tj. z przetasowaniem zbioru uczącego przed trenowaniem każdego modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "input_collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Głosowanie klas\n",
    "Nie zapominamy o randomizacji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Mamy $M=3$ modele, które dla $c=1\\dots5$ klas zwróciły prawdopodobieństwa:\n",
    "\n",
    "* $M_1$: `[0.1, 0.4, 0.5, 0.0, 0.0]`\n",
    "* $M_2$: `[0.1, 0.6, 0.2, 0.0, 0.1]`\n",
    "* $M_3$: `[0.1, 0.3, 0.4, 0.0, 0.2]`\n",
    "\n",
    "Która klasa zostanie wybrana wg liczby głosów na każdą z klas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "input_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## BAGGING = Bootstrap AGGregatING \n",
    "To samo co głosowanie klas, ale podczas randomizacji wybieramy $m$ przykładów **z powtórzeniami** (bootstrapping)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Ważony BAGGING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Ważenie podczas głosowania/uśredniania\n",
    "\n",
    "* W bagging, losujemy $m$ przykładów z **powtórzeniami**.\n",
    "* Prawie 40% danych nie jest wykorzystywanych, ponieważ $\\lim_{n \\rightarrow \\infty}\\left(1-\\frac{1}{n}\\right)^n = e^{-1} \\approx 0.368 $.\n",
    "* Te dane można wykorzystać jako **zestaw walidacyjny** i obliczyć **na nim** błąd $J_w(\\theta)$.\n",
    "* Mając $M$ klasyfikatorów, dla $i$-tego klasyfikatora obliczamy $w_i$:\n",
    "\n",
    "$$ w_i = \\dfrac{\\exp(-J_w(\\theta_i))}{\n",
    "\\sum_{j=1}^M \\exp(-J_w(\\theta_j))} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Klasyfikacja przez obliczenie **ważonych średnich prawdopodobieństw** (zbiór klas $C$, $y_i$ to odpowiedź $i$-tego klasyfikatora):\n",
    "$$y = \\mathop{\\mathrm{argmax}}_{c \\in C} \\dfrac{w_ip_{c,i}}{\\sum_{j=1}^{M} w_j p_{c,j}} $$\n",
    "gdzie $p_{c,i}$ jest prawdopodobieństwem wyboru klasy $c$ przez $i$-ty klasyfikator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Klasyfikacja przez **ważone głosowanie** (zbiór klas $C$, $y_i$ to odpowiedź $i$-tego klasyfikatora):\n",
    "$$y = \\mathop{\\mathrm{argmax}}_{c \\in C} \\sum_{i=1}^M w_i  I(c = y_i) $$\n",
    "gdzie \n",
    "$$I(A) = \\left\\{\\begin{array}{cl}1 & \\textrm{gdy zachodzi zdarzenie A}\\\\ 0 & \\textrm{wpp.}\\end{array}\\right.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Boosting\n",
    "\n",
    "Idea:\n",
    "\n",
    "* Budujemy kolejne klasyfikatory, zwiększając istotność tych przykładów trenujących, dla których poprzednie modele radziły sobie **słabiej**.\n",
    "* Może działać lepiej niż bagging, ale metoda wrażliwa na _przetrenowanie_ (więcej na następnym wykładzie).\n",
    "\n",
    "Najbardziej popularny algorytm to Adaboost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "input_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Stacking\n",
    "\n",
    "Idea: \n",
    "* Budujemy $M$ różnych klasyfikatorów.\n",
    "* Budujemy jeden **meta-klasyfikator** na podstawie wyników tych $M$ klasyfikatorów.\n",
    "\n",
    "(Jeśli mamy same regresory logistyczne, to jest to **prawie** dwuwarstwowa sieć neuronowa)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
