{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieci neuronowe - wprowadzenie\n",
    "\n",
    "Poniżej znajduje się implementacja prostej sieci neuronowej dla problemu klasyfikacji binarnej na przykładzie losowo wygenerowanego zestawu danych.\n",
    "\n",
    "W sieciach jednokierunkowych (ang. _feedforward_) wartości neuronów w $i$-tej warstwie są obliczane na podstawie wartości neuronów warstwy $i-1$. Mając daną $n$-warstwową sieć neuronową oraz jej parametry $\\Theta^{(1)}, \\ldots, \\Theta^{(n)} $ oraz $\\beta^{(1)}, \\ldots, \\beta^{(n)}$ liczymy: \n",
    "\n",
    "$$a^{(i)} = g^{(i)}\\left( a^{(i-1)} \\Theta^{(i)} + \\beta^{(i)} \\right). $$\n",
    "\n",
    "Gdzie $g^{(i)}$ to tzw. **funkcje aktywacji**\n",
    "\n",
    "### Zadania\n",
    "\n",
    "1. (15 pkt.) Rozwiń rekurencję dla poniższej sieci neuronowej, zapisując równania (w postaci Latexowej) dla $a^{(i)}$, wskaż funkcje aktywacji dla każdej warstwy oraz funkcję decyzyjną dla klasyfikacji. Podaj rozmiary wszystkich warstw oraz wymiary macierzy $\\theta^{(i)}$ i $\\beta^{(i)}$.\n",
    "\n",
    "1. (10 pkt.) Zaimplementuj funkcję `accuracy` i podaj końcową skuteczność klasyfikacji. Dodatkowo, skuteczność wypisuj wraz z wartością funkcji kosztu podczas trenowania modelu.\n",
    "\n",
    "1. (10 pkt.) Zbuduj sieci neuronowe dla różnych wielkości warstwy ukrytej $n=1,2,3,5,10,25$. Narysuj krzywe decyzyjne dla każdego modelu. Jakie zależności zaobserwowałeś?\n",
    "\n",
    "1. (15 pkt.) Zastosuj poniższą implementację sieci neuronowej do klasyfikacji zbioru z pliku `ex2data2.txt`. Dobierz odpowiednie parametry sieci (parametr $\\alpha$, liczba epok, wielkość warstwy ukrytej). Narysuj funkcję decyzyjną i podaj skuteczność klasyfikacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def generate_data():\n",
    "    # Keep results deterministic\n",
    "    np.random.seed(1234)\n",
    "    X, y = datasets.make_moons(200, noise=0.25)\n",
    "    # X, y = datasets.make_classification(200, 2, 2, 0)\n",
    "    return X, y\n",
    "\n",
    "def visualize(X, y, model=None):\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = 0.01\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    if model:\n",
    "        Z = predict(model, np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        plt.contourf(xx, yy, Z, cmap=plt.cm.viridis)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.viridis)\n",
    "    plt.show()\n",
    "\n",
    "def initialize_model(dim_in=2, dim_hid=3, dim_out=2):\n",
    "    # Keep results deterministic\n",
    "    np.random.seed(1234)\n",
    "    W1 = np.random.randn(dim_in, dim_hid) / np.sqrt(dim_in)\n",
    "    b1 = np.zeros((1, dim_hid))\n",
    "    W2 = np.random.randn(dim_hid, dim_out) / np.sqrt(dim_hid)\n",
    "    b2 = np.zeros((1, dim_out))\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def softmax(X):\n",
    "    e = np.exp(X)\n",
    "    return e / np.sum(e, axis=1, keepdims=True)\n",
    "\n",
    "def predict(model, X):\n",
    "    W1, b1, W2, b2 = model\n",
    "    z1 = X.dot(W1) + b1\n",
    "    a1 = np.tanh(z1)\n",
    "    z2 = a1.dot(W2) + b2\n",
    "    probs = softmax(z2)\n",
    "    return np.argmax(probs, axis=1)\n",
    "\n",
    "def calculate_cost(model, X, y):\n",
    "    W1, b1, W2, b2 = model\n",
    "    z1 = X.dot(W1) + b1\n",
    "    a1 = np.tanh(z1)\n",
    "    z2 = a1.dot(W2) + b2\n",
    "    probs = softmax(z2)\n",
    "    preds = probs[:, 1]\n",
    "    return -1. / len(y) * np.sum(\n",
    "        np.multiply(y, np.log(preds)) + np.multiply(1 - y, np.log(1 - preds)),\n",
    "        axis=0)\n",
    "\n",
    "def train(model, X, y, alpha=0.01, epochs=10000, debug=False):\n",
    "    W1, b1, W2, b2 = model\n",
    "    m = len(X)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Forward propagation\n",
    "        z1 = X.dot(W1) + b1\n",
    "        a1 = np.tanh(z1)\n",
    "        z2 = a1.dot(W2) + b2\n",
    "        probs = softmax(z2)\n",
    "\n",
    "        # Backpropagation\n",
    "        delta3 = probs\n",
    "        delta3[range(m), y] -= 1\n",
    "        dW2 = (a1.T).dot(delta3)\n",
    "        db2 = np.sum(delta3, axis=0, keepdims=True)\n",
    "        delta2 = delta3.dot(W2.T) * (1 - np.power(a1, 2))\n",
    "        dW1 = np.dot(X.T, delta2)\n",
    "        db1 = np.sum(delta2, axis=0)\n",
    "\n",
    "        # Parameter update\n",
    "        W1 -= alpha * dW1\n",
    "        b1 -= alpha * db1\n",
    "        W2 -= alpha * dW2\n",
    "        b2 -= alpha * db2\n",
    "\n",
    "        # Print loss\n",
    "        if debug and i % 1000 == 0:\n",
    "            model = (W1, b1, W2, b2)\n",
    "            print(\"Cost after iteration {}: {:.4f}\".format(i, calculate_cost(\n",
    "                model, X, y)))\n",
    "\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = generate_data()\n",
    "visualize(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = train(initialize_model(), X, y, debug=True)\n",
    "visualize(X, y, model)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
